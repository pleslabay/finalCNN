{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Entrega2 Trabajo Final CNN - Style Transfer.ipynb","provenance":[{"file_id":"13oCPFg9a8RJyGw2BxHVWLVnx-YAxJZaO","timestamp":1582253213302},{"file_id":"https://github.com/deeplearning-itba/cnn/blob/master/Trabajo_Final_CNN_Style_Transfer.ipynb","timestamp":1582229849777}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"qCY6UbkkI9_N","colab_type":"text"},"source":["# Style Transfer\n","\n","<img src=\"https://i0.wp.com/chelseatroy.com/wp-content/uploads/2018/12/neural_style_transfer.png?resize=768%2C311&ssl=1\">\n","\n","La idea de este trabajo final es reproducir el siguiente paper:\n","\n","https://arxiv.org/pdf/1508.06576.pdf\n","\n","El objetivo es transferir el estilo de una imagen dada a otra imagen distinta. \n","\n","Como hemos visto en clase, las primeras capas de una red convolucional se activan ante la presencia de ciertos patrones vinculados a detalles muy pequeños.\n","\n","A medida que avanzamos en las distintas capas de una red neuronal convolucional, los filtros se van activando a medida que detectan patrones de formas cada vez mas complejos.\n","\n","Lo que propone este paper es asignarle a la activación de las primeras capas de una red neuronal convolucional (por ejemplo VGG19) la definición del estilo y a la activación de las últimas capas de la red neuronal convolucional, la definición del contenido.\n","\n","La idea de este paper es, a partir de dos imágenes (una que aporte el estilo y otra que aporte el contenido) analizar cómo es la activación de las primeras capas para la imagen que aporta el estilo y cómo es la activación de las últimas capas de la red convolucional para la imagen que aporta el contenido. A partir de esto se intentará sintetizar una imagen que active los filtros de las primeras capas que se activaron con la imagen que aporta el estilo y los filtros de las últimas capas que se activaron con la imagen que aporta el contenido.\n","\n","A este procedimiento se lo denomina neural style transfer.\n","\n","# En este trabajo se deberá leer el paper mencionado y en base a ello, entender la implementación que se muestra a continuación y contestar preguntas sobre la misma.\n","\n","# Una metodología posible es hacer una lectura rápida del paper (aunque esto signifique no entender algunos detalles del mismo) y luego ir analizando el código y respondiendo las preguntas. A medida que se planteen las preguntas, volviendo a leer secciones específicas del paper terminará de entender los detalles que pudieran haber quedado pendientes.\n","\n","Lo primero que haremos es cargar dos imágenes, una que aporte el estilo y otra que aporte el contenido. A tal fin utilizaremos imágenes disponibles en la web."]},{"cell_type":"code","metadata":{"id":"kyHsa2t0SxZi","colab_type":"code","outputId":"c6b5c95b-fa29-436f-9bfc-dd6b4c7487fb","executionInfo":{"status":"ok","timestamp":1582253551361,"user_tz":180,"elapsed":10149,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":435}},"source":["# Imagen para estilo\n","!wget https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n","\n","# Imagen para contenido\n","!wget https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n","\n","# Creamos el directorio para los archivos de salida\n","!mkdir /content/output"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2020-02-21 02:52:20--  https://upload.wikimedia.org/wikipedia/commons/5/52/La_noche_estrellada1.jpg\n","Resolving upload.wikimedia.org (upload.wikimedia.org)... 91.198.174.208, 2620:0:862:ed1a::2:b\n","Connecting to upload.wikimedia.org (upload.wikimedia.org)|91.198.174.208|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 223725 (218K) [image/jpeg]\n","Saving to: ‘La_noche_estrellada1.jpg.1’\n","\n","\r          La_noche_   0%[                    ]       0  --.-KB/s               \rLa_noche_estrellada 100%[===================>] 218.48K  --.-KB/s    in 0.02s   \n","\n","2020-02-21 02:52:20 (13.2 MB/s) - ‘La_noche_estrellada1.jpg.1’ saved [223725/223725]\n","\n","--2020-02-21 02:52:22--  https://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Neckarfront_T%C3%BCbingen_Mai_2017.jpg/775px-Neckarfront_T%C3%BCbingen_Mai_2017.jpg\n","Resolving upload.wikimedia.org (upload.wikimedia.org)... 91.198.174.208, 2620:0:862:ed1a::2:b\n","Connecting to upload.wikimedia.org (upload.wikimedia.org)|91.198.174.208|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 153015 (149K) [image/jpeg]\n","Saving to: ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.1’\n","\n","775px-Neckarfront_T 100%[===================>] 149.43K  --.-KB/s    in 0.01s   \n","\n","2020-02-21 02:52:22 (10.3 MB/s) - ‘775px-Neckarfront_Tübingen_Mai_2017.jpg.1’ saved [153015/153015]\n","\n","mkdir: cannot create directory ‘/content/output’: File exists\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NIxH20o2eFoc","colab_type":"code","outputId":"bd62f0a0-9f85-4a84-f7b3-43dd6ae10a40","executionInfo":{"status":"ok","timestamp":1582253552483,"user_tz":180,"elapsed":11186,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["from keras.preprocessing.image import load_img, save_img, img_to_array\n","import numpy as np\n","from scipy.optimize import fmin_l_bfgs_b\n","import time\n","import argparse\n","\n","from keras.applications import vgg19\n","from keras import backend as K\n","from pathlib import Path"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"iLkV1bnFl_tK","colab_type":"code","colab":{}},"source":["# Definimos las imagenes que vamos a utilizar, y el directorio de salida\n","\n","base_image_path = Path(\"/content/775px-Neckarfront_Tübingen_Mai_2017.jpg\")\n","style_reference_image_path = Path(\"/content/La_noche_estrellada1.jpg\")\n","result_prefix = Path(\"/content/output\")\n","\n","base_image_path = Path(\"davinci.jpg\")\n","style_reference_image_path = Path(\"picasso3.jpg\")\n","iterations = 100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gz2PeGfpeYzj","colab_type":"text"},"source":["# 1) En base a lo visto en el paper ¿Qué significan los parámetros definidos en la siguiente celda?\n","\n","Respuesta:\n","\n","*content_weight* corresponde a alfa, *style_weight* a beta.\n","\n","Ambos representan la ponderación relativa en la loss de optimizacion del \"error\" de contenido y de estilo de la nueva imagen creada, respecto a lo decodificado por la VGG (pre-entrenada) sobre las imagenes de entrada\n","\n","*Total_variation_weight* no se encuentra en el paper original, pero según la implementacion de la notebook, corresponde a una penalidad tipo L2 sobre la diferencia entre pixels adyacentes de la nueva imagen creada: [(imagen creada - shift de 1 pixel ver).^2 + (imagen creada - shift 1 pixel hor).^2].^1.25, y todo eso sumado pixel a pixel en los tres canales.\n","\n","No es un Learing Rate porque no disminuye el update por gradiente, ni Regularización porque no actua sobre los pesos. Simplemente penaliza cambios bruscos entre pixels cercanos. "]},{"cell_type":"code","metadata":{"id":"P9Dt3aaEmJWS","colab_type":"code","colab":{}},"source":["content_weight = 1    #(alpha)\n","style_weight = 10   #(beta)\n","ratio = content_weight/style_weight\n","\n","total_variation_weight = 0.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CQQJOhCVuse6","colab_type":"code","colab":{}},"source":["# Definimos el tamaño de las imágenes a utilizar\n","width, height = load_img(base_image_path).size\n","img_nrows = 400\n","img_ncols = int(width * img_nrows / height)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gg2ct-8agm1E","colab_type":"text"},"source":["# 2) Explicar qué hace la siguiente celda. En especial las últimas dos líneas de la función antes del return. ¿Por qué?\n","\n","Ayuda: https://keras.io/applications/\n","\n","Respuesta:\n","\n","carga la imagen, en rgb\n","\n","luego transforma el objeto en un array de img_nrows x img_ncols x 3(rgb)\n","\n","expande a un array de 1 x img_nrows x img_ncols x 3(rgb). Esto es necesario porque VGG espera un batch de imagenes a procesar\n","\n","pasa la imagen por un \"acomodador\" de niveles de color, para que sean compatibles con los usados para el entrenamiento previo de VGG."]},{"cell_type":"code","metadata":{"id":"tAkljg4zuzYd","colab_type":"code","colab":{}},"source":["def preprocess_image(image_path):\n","    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n","    img = img_to_array(img)\n","    img = np.expand_dims(img, axis=0)\n","    img = vgg19.preprocess_input(img)\n","    return img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KTf0YDSagt10","colab_type":"text"},"source":["# 3) Habiendo comprendido lo que hace la celda anterior, explique de manera muy concisa qué hace la siguiente celda. ¿Qué relación tiene con la celda anterior?\n","\n","Respuesta:\n","\n","rearmando el array del flatten (en el optimizador) al formato/tamaño inicial, \n","\n","luego trabaja sobre los brillos: está sumando valores medios, inviertiendo el orden de los colores y clippeando los brillos en el rango 0-255\n","\n","Basicamente \"preprocess_input\" a la inversa..."]},{"cell_type":"code","metadata":{"id":"y5LaTrsAu14z","colab_type":"code","colab":{}},"source":["def deprocess_image(x):\n","    x = x.reshape((img_nrows, img_ncols, 3))\n","    # Remove zero-center by mean pixel\n","    x[:, :, 0] += 103.939\n","    x[:, :, 1] += 116.779\n","    x[:, :, 2] += 123.68\n","    # 'BGR'->'RGB'\n","    x = x[:, :, ::-1]\n","    x = np.clip(x, 0, 255).astype('uint8')\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HYNio09mu4S3","colab_type":"code","colab":{}},"source":["# get tensor representations of our images\n","# K.variable convierte un numpy array en un tensor, para \n","base_image = K.variable(preprocess_image(base_image_path))\n","style_reference_image = K.variable(preprocess_image(style_reference_image_path))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1Lbw02Uu--o","colab_type":"code","outputId":"371ec21d-258c-4781-dfd0-a38ab6cd988e","executionInfo":{"status":"ok","timestamp":1582253552499,"user_tz":180,"elapsed":10805,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RJEi0YI3Uzrm","colab_type":"text"},"source":["Aclaración:\n","\n","La siguiente celda sirve para procesar las tres imagenes (contenido, estilo y salida) en un solo batch."]},{"cell_type":"code","metadata":{"id":"gGO_jGFfvEbF","colab_type":"code","colab":{}},"source":["# combine the 3 images into a single Keras tensor\n","input_tensor = K.concatenate([base_image,\n","                              style_reference_image,\n","                              combination_image], axis=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tdG59VRavHGB","colab_type":"code","outputId":"fa13a7e0-2263-4359-84e4-2c94aab20057","executionInfo":{"status":"ok","timestamp":1582253565014,"user_tz":180,"elapsed":23237,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":399}},"source":["# build the VGG19 network with our 3 images as input\n","# the model will be loaded with pre-trained ImageNet weights\n","model = vgg19.VGG19(input_tensor=input_tensor,\n","                    weights='imagenet', include_top=False)\n","print('Model loaded.')\n","\n","# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n","outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n","80142336/80134624 [==============================] - 3s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","Model loaded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gzb7E3PIblzr","colab_type":"code","outputId":"94ff9535-1193-4f69-9c3a-3a4ec86e0a2e","executionInfo":{"status":"ok","timestamp":1582253565017,"user_tz":180,"elapsed":23197,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["outputs_dict['block4_conv2'][0, :, :, :]"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor 'strided_slice:0' shape=(50, 39, 512) dtype=float32>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"70-vs_jZkKVc","colab_type":"text"},"source":["# 4) En la siguientes celdas:\n","\n","- ¿Qué es la matriz de Gram?¿Para qué se usa?\n","- ¿Por qué se permutan las dimensiones de x?"]},{"cell_type":"markdown","metadata":{"id":"dIq192hWVs_D","colab_type":"text"},"source":["Respuesta:\n","\n","La *matrix Gram* es una matriz de (auto)correlación de features=respuesta de filtros, en una imagen feed_forward por la red.\n","\"It consists of the correlations between the different filter responses\n","over the spatial extent of the feature maps\"\n","\n","La uso para ir alterando la imagen generada hasta que minimice(por gradientes) la diferencia con los features obtenidos a partir de la imagen que aporta el estilo. \n","Voy alterando la imagen inicial 'ruido_blanco' para que active la red de la misma forma que la imagen 'style'\n","\n","Se *permutan* porque la sumatoria del paper es sobre el maxpooling (averagepool debiera ser en realidad!) de cada filtro pasado sobre todo el layer que le corresponde.\n","Entonces el flatten me deja un shape('n_filtros' , img_nrows*img_ncols/2^nro_pooling), listo para hacer la sumatoria del paper con el producto escalar.\n"]},{"cell_type":"code","metadata":{"id":"K1FODPATvJ1k","colab_type":"code","colab":{}},"source":["def gram_matrix(x):\n","    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n","    gram = K.dot(features, K.transpose(features))\n","    return gram"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vBQkKFY0Rbx-","colab_type":"text"},"source":["# 5) Losses:\n","\n","Explicar qué mide cada una de las losses en las siguientes tres celdas.\n","\n","Rta:\n","\n","*Content_loss:* corresponde a la diferencia de activación en feed_forward en un layer particular de la VGG (o sea ya features), entre la imagen base -que aporta el contenido- y la imagen nueva generada.\n","\n","*Style_loss:* corresponde a la suma de 5 diferencias de activación en feed_forward (o sea ya features) contra 5 layers particulares de la VGG, esta vez entre la imagen que aporta el estilo y la imagen nueva generada. La loss está escalada por el nro_filtros^2 y el tamaño^2 (pero no exactamente como dice el paper)\n","\n","*Total_variation_loss:* no se encuentra en el paper original, pero según la implementacion de la notebook, corresponde a una penalidad tipo L2 sobre la diferencia entre pixels adyacentes de la nueva imagen creada: [(imagen creada - shift de 1 pixel ver).^2 + (imagen creada - shift 1 pixel hor).^2].^1.25, y todo eso sumado pixel a pixel en los tres canales.\n","\n","No es un Learing Rate porque no disminuye el update por gradiente, ni Regularización porque no actua sobre los pesos. Simplemente penaliza cambios bruscos entre pixels adyacentes, y no trabaja con los features!\n"]},{"cell_type":"code","metadata":{"id":"1-Gt0ahWvN6q","colab_type":"code","colab":{}},"source":["def style_loss(style, combination):\n","    assert K.ndim(style) == 3\n","    assert K.ndim(combination) == 3\n","    S = gram_matrix(style)\n","    C = gram_matrix(combination)\n","    channels = 3\n","    size = img_nrows * img_ncols\n","    return K.sum(K.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XCqnju5RvQCo","colab_type":"code","colab":{}},"source":["def content_loss(base, combination):\n","    return K.sum(K.square(combination - base))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"udEp5h31vRnY","colab_type":"code","colab":{}},"source":["def total_variation_loss(x):\n","    assert K.ndim(x) == 4\n","    a = K.square(\n","        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n","    b = K.square(\n","        x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n","    return K.sum(K.pow(a + b, 1.25))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-65vcinbvTZ0","colab_type":"code","colab":{}},"source":["# Armamos la loss total\n","loss = K.variable(0.0)\n","layer_features = outputs_dict['block5_conv2']\n","base_image_features = layer_features[0, :, :, :]\n","combination_features = layer_features[2, :, :, :]\n","loss = loss + content_weight * content_loss(base_image_features,\n","                                            combination_features)\n","\n","feature_layers = ['block1_conv1', 'block2_conv1',\n","                  'block3_conv1', 'block4_conv1',\n","                  'block5_conv1']\n","for layer_name in feature_layers:\n","    layer_features = outputs_dict[layer_name]\n","    style_reference_features = layer_features[1, :, :, :] \n","    combination_features = layer_features[2, :, :, :]\n","    sl = style_loss(style_reference_features, combination_features)\n","    loss = loss + (style_weight / len(feature_layers)) * sl\n","loss = loss + total_variation_weight * total_variation_loss(combination_image)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbz4n1OhvV2K","colab_type":"code","outputId":"f3fbcb37-2ecd-4fd6-93bf-13d55e9b0ed9","executionInfo":{"status":"ok","timestamp":1582253565419,"user_tz":180,"elapsed":23407,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["grads = K.gradients(loss, combination_image)\n","\n","outputs = [loss]\n","if isinstance(grads, (list, tuple)):\n","    outputs += grads\n","else:\n","    outputs.append(grads)\n","\n","f_outputs = K.function([combination_image], outputs)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1JbydbOaVcvU","colab_type":"text"},"source":["# 6) Explique el propósito de las siguientes tres celdas. ¿Qué hace la función fmin_l_bfgs_b? ¿En qué se diferencia con la implementación del paper? ¿Se puede utilizar alguna alternativa?\n","\n","Respuesta:\n","\n","*En la celda anteror computamos el gradiente de la loss respecto de los pixels de la combination_image que se va generando en la red. También estamos generando una serie de tensores y placeholders para los gradientes y la loss\n","\n","*Luego en la primera celda, definimos una funcion que manipula los gradientes y la loss para dejarlos en el formato correcto\n","\n","*Por ultimo generamos una clase que entrega 2 funciones 'callable' de loss y gradiente, como lo requiere el optimizador empleado. Se hace esto de la clase simplemente porque se supone (no tengo herramientas para verificar esto) que es mas rápido computacionalmente.\n","\n","En cuanto al minimizador/optimizador de loss, el paper no indica nada sobre cual usar. Finaliza la explicación con la expresión de la loss. Como aclaramos antes, la loss de la notebook incorpora un término para suavizar pixels adyacentes que no es parte del trabajo original.\n","También encontré algunas diferencias en el cálculo de style_loss, sobre como se obtiene el nro_filtros y el tamaño, que no se hace correctamente aqui.\n","\n","Pero la principal diferencia es que en esta implementacion **NO** estamos partiendo de una imagen ruido blanco, sino de la imagen base para hacer el grad descent.\n","\n","Justamente *fmin_l_bfgs_b* es el minimizador por gradientes multivariable que se ocupa de ir alterando la imagen compuesta para reducir la loss.\n","Es un linesearch mutivariable, optimizado para trabajar con menos memoria. La última b proviene de una variante que admite poner constraints a los valores de cada varaible, en este caso sería la luminosidad del pixel. NO se está usando esta capacidad.\n","\n","Solo podríamos utilizar el tipo de optimizadores visto en el curso (Adam/RMSProp, Adamax) si aceptaramos usar los gradientes aproximados, ya que para esta loss en particular, no van a saber como obtenerlos. Por eso el cálculo externo con la funcion K.gradients."]},{"cell_type":"code","metadata":{"id":"zVE1_qemvZeN","colab_type":"code","colab":{}},"source":["def eval_loss_and_grads(x):\n","    x = x.reshape((1, img_nrows, img_ncols, 3))\n","    outs = f_outputs([x])\n","    loss_value = outs[0]\n","    if len(outs[1:]) == 1:\n","        grad_values = outs[1].flatten().astype('float64')\n","    else:\n","        grad_values = np.array(outs[1:]).flatten().astype('float64')\n","    return loss_value, grad_values\n","\n","# this Evaluator class makes it possible\n","# to compute loss and gradients in one pass\n","# while retrieving them via two separate functions,\n","# \"loss\" and \"grads\". This is done because scipy.optimize\n","# requires separate functions for loss and gradients,\n","# but computing them separately would be inefficient."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qbl9roIgvdb1","colab_type":"code","colab":{}},"source":["class Evaluator(object):\n","\n","    def __init__(self):\n","        self.loss_value = None\n","        self.grads_values = None\n","\n","    def loss(self, x):\n","        assert self.loss_value is None\n","        loss_value, grad_values = eval_loss_and_grads(x)\n","        self.loss_value = loss_value\n","        self.grad_values = grad_values\n","        return self.loss_value\n","\n","    def grads(self, x):\n","        assert self.loss_value is not None\n","        grad_values = np.copy(self.grad_values)\n","        self.loss_value = None\n","        self.grad_values = None\n","        return grad_values"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Sb0yOEl-WOE6","colab_type":"text"},"source":["# 7) Ejecute la siguiente celda y observe las imágenes de salida en cada iteración."]},{"cell_type":"markdown","metadata":{"id":"SkiJtofbWWy1","colab_type":"text"},"source":["# 8) Generar imágenes para distintas combinaciones de pesos de las losses. Explicar las diferencias. (Adjuntar las imágenes generadas como archivos separados.)\n","\n","Respuesta:"]},{"cell_type":"markdown","metadata":{"id":"sWQLndz2axju","colab_type":"text"},"source":["# 9) Cambiar las imágenes de contenido y estilo por unas elegidas por usted. Adjuntar el resultado.\n","\n","Respuesta:"]},{"cell_type":"code","metadata":{"id":"vsv7McNpc4iP","colab_type":"code","outputId":"a5fcd9f0-2b8b-47a8-9f51-8e73de866cec","executionInfo":{"status":"ok","timestamp":1582253992036,"user_tz":180,"elapsed":449873,"user":{"displayName":"Pablo Enrique Leslabay","photoUrl":"","userId":"03530669571146255661"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["evaluator = Evaluator()\n","\n","# run scipy-based optimization (L-BFGS) over the pixels of the generated image\n","# so as to minimize the neural style loss\n","x = preprocess_image(base_image_path)\n","\n","for i in range(iterations):\n","    #print('Start of iteration', i)\n","    start_time = time.time()\n","    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n","                                     fprime=evaluator.grads, maxfun=20)\n","    print('Current loss value:', min_val)\n","    # save current generated image\n","    img = deprocess_image(x.copy())\n","    fname = result_prefix / ('2output_at_iteration_%d.png' % i)\n","    save_img(fname, img)\n","    end_time = time.time()\n","    #print('Image saved as', fname)\n","    print('Iteration %d completed in %ds' % (i, end_time - start_time))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Current loss value: 133847000000.0\n","Iteration 0 completed in 12s\n","Current loss value: 51489464000.0\n","Iteration 1 completed in 3s\n","Current loss value: 33208848000.0\n","Iteration 2 completed in 3s\n","Current loss value: 24786082000.0\n","Iteration 3 completed in 3s\n","Current loss value: 20169525000.0\n","Iteration 4 completed in 3s\n","Current loss value: 16266598000.0\n","Iteration 5 completed in 4s\n","Current loss value: 14021681000.0\n","Iteration 6 completed in 3s\n","Current loss value: 12260043000.0\n","Iteration 7 completed in 4s\n","Current loss value: 11047502000.0\n","Iteration 8 completed in 4s\n","Current loss value: 10164330000.0\n","Iteration 9 completed in 4s\n","Current loss value: 9293162000.0\n","Iteration 10 completed in 4s\n","Current loss value: 8685304000.0\n","Iteration 11 completed in 4s\n","Current loss value: 8211998000.0\n","Iteration 12 completed in 4s\n","Current loss value: 7796943400.0\n","Iteration 13 completed in 4s\n","Current loss value: 7414484500.0\n","Iteration 14 completed in 4s\n","Current loss value: 7057010700.0\n","Iteration 15 completed in 4s\n","Current loss value: 6825419000.0\n","Iteration 16 completed in 4s\n","Current loss value: 6535703600.0\n","Iteration 17 completed in 4s\n","Current loss value: 6305125400.0\n","Iteration 18 completed in 4s\n","Current loss value: 6141626400.0\n","Iteration 19 completed in 4s\n","Current loss value: 5951712000.0\n","Iteration 20 completed in 4s\n","Current loss value: 5745312300.0\n","Iteration 21 completed in 4s\n","Current loss value: 5577407500.0\n","Iteration 22 completed in 4s\n","Current loss value: 5425876500.0\n","Iteration 23 completed in 4s\n","Current loss value: 5257697000.0\n","Iteration 24 completed in 4s\n","Current loss value: 5152034000.0\n","Iteration 25 completed in 4s\n","Current loss value: 5054715000.0\n","Iteration 26 completed in 4s\n","Current loss value: 4968610000.0\n","Iteration 27 completed in 4s\n","Current loss value: 4890059000.0\n","Iteration 28 completed in 4s\n","Current loss value: 4814702000.0\n","Iteration 29 completed in 4s\n","Current loss value: 4746999000.0\n","Iteration 30 completed in 4s\n","Current loss value: 4675216400.0\n","Iteration 31 completed in 4s\n","Current loss value: 4598143500.0\n","Iteration 32 completed in 4s\n","Current loss value: 4530199600.0\n","Iteration 33 completed in 4s\n","Current loss value: 4468132400.0\n","Iteration 34 completed in 4s\n","Current loss value: 4409855000.0\n","Iteration 35 completed in 4s\n","Current loss value: 4350795000.0\n","Iteration 36 completed in 4s\n","Current loss value: 4294876000.0\n","Iteration 37 completed in 4s\n","Current loss value: 4250619600.0\n","Iteration 38 completed in 4s\n","Current loss value: 4189905000.0\n","Iteration 39 completed in 4s\n","Current loss value: 4141526300.0\n","Iteration 40 completed in 4s\n","Current loss value: 4089545700.0\n","Iteration 41 completed in 4s\n","Current loss value: 4052926500.0\n","Iteration 42 completed in 4s\n","Current loss value: 4008302000.0\n","Iteration 43 completed in 4s\n","Current loss value: 3961546200.0\n","Iteration 44 completed in 4s\n","Current loss value: 3921889500.0\n","Iteration 45 completed in 4s\n","Current loss value: 3875017700.0\n","Iteration 46 completed in 4s\n","Current loss value: 3832281300.0\n","Iteration 47 completed in 4s\n","Current loss value: 3797495600.0\n","Iteration 48 completed in 4s\n","Current loss value: 3758052000.0\n","Iteration 49 completed in 4s\n","Current loss value: 3728323800.0\n","Iteration 50 completed in 4s\n","Current loss value: 3695675400.0\n","Iteration 51 completed in 4s\n","Current loss value: 3666978300.0\n","Iteration 52 completed in 4s\n","Current loss value: 3634046500.0\n","Iteration 53 completed in 4s\n","Current loss value: 3609068000.0\n","Iteration 54 completed in 4s\n","Current loss value: 3576853200.0\n","Iteration 55 completed in 4s\n","Current loss value: 3550209500.0\n","Iteration 56 completed in 4s\n","Current loss value: 3524087300.0\n","Iteration 57 completed in 4s\n","Current loss value: 3495608600.0\n","Iteration 58 completed in 4s\n","Current loss value: 3469428000.0\n","Iteration 59 completed in 4s\n","Current loss value: 3440463400.0\n","Iteration 60 completed in 4s\n","Current loss value: 3416084000.0\n","Iteration 61 completed in 4s\n","Current loss value: 3393716500.0\n","Iteration 62 completed in 4s\n","Current loss value: 3364161000.0\n","Iteration 63 completed in 4s\n","Current loss value: 3339978200.0\n","Iteration 64 completed in 4s\n","Current loss value: 3313843000.0\n","Iteration 65 completed in 4s\n","Current loss value: 3280744700.0\n","Iteration 66 completed in 4s\n","Current loss value: 3255117600.0\n","Iteration 67 completed in 4s\n","Current loss value: 3231785700.0\n","Iteration 68 completed in 4s\n","Current loss value: 3212167700.0\n","Iteration 69 completed in 4s\n","Current loss value: 3194480400.0\n","Iteration 70 completed in 4s\n","Current loss value: 3179385300.0\n","Iteration 71 completed in 4s\n","Current loss value: 3151624700.0\n","Iteration 72 completed in 4s\n","Current loss value: 3126923300.0\n","Iteration 73 completed in 4s\n","Current loss value: 3110180600.0\n","Iteration 74 completed in 4s\n","Current loss value: 3095492000.0\n","Iteration 75 completed in 4s\n","Current loss value: 3083239000.0\n","Iteration 76 completed in 4s\n","Current loss value: 3068497000.0\n","Iteration 77 completed in 4s\n","Current loss value: 3054868000.0\n","Iteration 78 completed in 4s\n","Current loss value: 3043406800.0\n","Iteration 79 completed in 4s\n","Current loss value: 3030532000.0\n","Iteration 80 completed in 4s\n","Current loss value: 3015021800.0\n","Iteration 81 completed in 4s\n","Current loss value: 2999287600.0\n","Iteration 82 completed in 4s\n","Current loss value: 2980070400.0\n","Iteration 83 completed in 4s\n","Current loss value: 2962928000.0\n","Iteration 84 completed in 4s\n","Current loss value: 2946562600.0\n","Iteration 85 completed in 4s\n","Current loss value: 2931277300.0\n","Iteration 86 completed in 4s\n","Current loss value: 2917066500.0\n","Iteration 87 completed in 4s\n","Current loss value: 2903441200.0\n","Iteration 88 completed in 4s\n","Current loss value: 2893006300.0\n","Iteration 89 completed in 4s\n","Current loss value: 2882697200.0\n","Iteration 90 completed in 4s\n","Current loss value: 2873085400.0\n","Iteration 91 completed in 4s\n","Current loss value: 2863278600.0\n","Iteration 92 completed in 4s\n","Current loss value: 2854573800.0\n","Iteration 93 completed in 4s\n","Current loss value: 2845798700.0\n","Iteration 94 completed in 4s\n","Current loss value: 2836282600.0\n","Iteration 95 completed in 4s\n","Current loss value: 2826156500.0\n","Iteration 96 completed in 4s\n","Current loss value: 2815230200.0\n","Iteration 97 completed in 4s\n","Current loss value: 2801306400.0\n","Iteration 98 completed in 4s\n","Current loss value: 2788805000.0\n","Iteration 99 completed in 4s\n"],"name":"stdout"}]}]}